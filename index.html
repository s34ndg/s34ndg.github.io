<!DOCTYPE html>
<html>
<head>
    <title>Web Audio App</title>
    <style>
        /* Add CSS styles to customize the UI */
    </style>
</head>
<body>
<h1>Web Audio App</h1>

<!-- Existing code -->
<h2>Audio Settings</h2>
<form id="settingsForm">
    <label for="audioThreshold">Audio Threshold (dB):</label>
    <input type="number" id="audioThreshold" value="60" required>
    <br>
    <label for="silenceDuration">Silence Duration (seconds):</label>
    <input type="number" id="silenceDuration" value="5" required>
    <br>
    <button type="submit">Apply Settings</button>
</form>

<h2>Calibration</h2>
<p>Ambient Noise Level: <span id="ambientNoiseLevel">-</span> dB</p>
<button id="calibrateButton">Calibrate</button>

<h2>Status</h2>
<p id="statusText">Not listening</p>
<button id="startButton">Start Listening</button>

<footer>Version 0.0.17</footer>

<script>
        // Variables
        let audioThreshold = 60; // Default audio threshold in dB
        let silenceDuration = 5; // Default silence duration in seconds
        let ambientNoiseLevel = 0; // Ambient noise level (calibrated value)
        let isListening = false; // Listening status

        // Function to check for audio silence and show notification
        function checkAudioSilence() {
            const audioContext = new AudioContext();
            const analyser = audioContext.createAnalyser();
            const bufferLength = analyser.fftSize;

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);

                    setInterval(() => {
                        const dataArray = new Uint8Array(bufferLength);
                        analyser.getByteTimeDomainData(dataArray);

                        const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
                        const audioLevel = 20 * Math.log10(average / 128);

                        if (audioLevel <= audioThreshold) {
                            silenceDuration -= 1;
                        } else {
                            silenceDuration = parseInt(document.getElementById('silenceDuration').value);
                        }

                        if (silenceDuration === 0) {
                            showNotification('Silence Detected', 'No audio detected for the specified period');
                        }
                    }, 1000); // Check audio levels every second
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                });
        }

        // Function to show a pop-up notification
        function showNotification(title, message) {
            if (Notification.permission === 'granted') {
                new Notification(title, { body: message });
            } else if (Notification.permission !== 'denied') {
                Notification.requestPermission().then(permission => {
                    if (permission === 'granted') {
                        new Notification(title, { body: message });
                    }
                });
            }
        }

        // Function to start the audio silence detection
        function startDetection() {
            // Reset silence duration
            silenceDuration = parseInt(document.getElementById('silenceDuration').value);
            isListening = true;
            document.getElementById('statusText').textContent = 'Listening...';

            checkAudioSilence();
        }

        // Function to handle form submission
        function handleFormSubmit(event) {
            event.preventDefault();
            audioThreshold = parseInt(document.getElementById('audioThreshold').value);
            silenceDuration = parseInt(document.getElementById('silenceDuration').value);
        }

        // Function to calibrate the ambient noise level
        function calibrateNoiseLevel() {
            const audioContext = new AudioContext();
            const analyser = audioContext.createAnalyser();
            const bufferLength = analyser.fftSize;

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);

                    setInterval(() => {
                        const dataArray = new Uint8Array(bufferLength);
                        analyser.getByteTimeDomainData(dataArray);

                        const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
                        const audioLevel = 20 * Math.log10(average / 128);

                        ambientNoiseLevel = audioLevel;
                        document.getElementById('ambientNoiseLevel').textContent = audioLevel.toFixed(2) + ' dB';
                    }, 1000); // Update ambient noise level every second
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                });
        }

        // Add event listener to start button
        const startButton = document.getElementById('startButton');
        startButton.addEventListener('click', startDetection);

        // Add event listener to form submit
        const settingsForm = document.getElementById('settingsForm');
        settingsForm.addEventListener('submit', handleFormSubmit);

        // Add event listener to calibrate button
        const calibrateButton = document.getElementById('calibrateButton');
        calibrateButton.addEventListener('click', calibrateNoiseLevel);
    </script>
</body>
</html>
