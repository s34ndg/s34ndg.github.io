<!DOCTYPE html>
<html>
<head>
    <title>Web Audio App</title>
    <style>
        /* Add CSS styles to customize the UI */
    </style>
</head>
<body>
<h1>Web Audio App</h1>
<button id="startButton">Start</button>
<p id="statusText">Not listening</p>

<script>
        // Check for browser compatibility
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            alert('Web Audio API is not supported in this browser.');
        }

        // Get references to UI elements
        const startButton = document.getElementById('startButton');
        const statusText = document.getElementById('statusText');

        let isListening = false;
        let audioContext = null;
        let audioStream = null;
        let audioSource = null;
        let audioProcessor = null;
        const audioThreshold = -60; // Adjust this value based on your requirements

        startButton.addEventListener('click', toggleListening);

        function toggleListening() {
            if (!isListening) {
                requestAudioPermission();
            } else {
                stopListening();
            }
        }

        function requestAudioPermission() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(startListening)
                .catch(handleAudioPermissionError);
        }

        function handleAudioPermissionError(error) {
            console.error('Audio permission denied:', error);
            statusText.textContent = 'Permission denied. Please allow access to the microphone.';
        }

        function startListening(stream) {
            isListening = true;
            startButton.textContent = 'Stop';
            statusText.textContent = 'Listening...';

            audioContext = new AudioContext();
            audioStream = stream;
            audioSource = audioContext.createMediaStreamSource(audioStream);
            audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);

            audioProcessor.onaudioprocess = processAudio;

            audioSource.connect(audioProcessor);
            audioProcessor.connect(audioContext.destination);
        }

        function stopListening() {
            isListening = false;
            startButton.textContent = 'Start';
            statusText.textContent = 'Not listening';

            audioProcessor.onaudioprocess = null;

            audioSource.disconnect();
            audioProcessor.disconnect();
            audioStream.getTracks().forEach(track => track.stop());

            audioContext = null;
            audioStream = null;
            audioSource = null;
            audioProcessor = null;
        }

        function processAudio(event) {
            const input = event.inputBuffer.getChannelData(0);
            let sum = 0;

            for (let i = 0; i < input.length; i++) {
                sum += input[i] ** 2;
            }

            const rms = Math.sqrt(sum / input.length);
            const db = 20 * Math.log10(rms);

            if (db < audioThreshold) {
                // Perform the action when the audio level is below the threshold
                // For example, you can trigger vibration or ringtone here
            }
        }
    </script>

    <script type="module">
      // Import the functions you need from the SDKs you need
      import { initializeApp } from "https://www.gstatic.com/firebasejs/9.22.2/firebase-app.js";
      // TODO: Add SDKs for Firebase products that you want to use
      // https://firebase.google.com/docs/web/setup#available-libraries
      // Your web app's Firebase configuration
      const firebaseConfig = {
        apiKey: "AIzaSyASGfe8Q0voyc51zY19R3pTWbliEfXh8z4",
        authDomain: "speak2focus.firebaseapp.com",
        projectId: "speak2focus",
        storageBucket: "speak2focus.appspot.com",
        messagingSenderId: "192130724331",
        appId: "1:192130724331:web:edb861b2ecb116f302e9ae"
      };
      // Initialize Firebase
      const app = initializeApp(firebaseConfig);
    </script>

</body>
</html>
